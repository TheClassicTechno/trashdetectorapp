{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZQnMtjktUwcVgMHlflc4C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheClassicTechno/trashdetectorapp/blob/main/Final_DebriDetec_CNN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DebriDetec CNN Model\n",
        "\n",
        "achieved >95% accuracy consistently on the Taco Custom Dataset."
      ],
      "metadata": {
        "id": "0i54wSuEld8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##mount drive to access dataset"
      ],
      "metadata": {
        "id": "HxLRhOO0lpif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "A6i0R_D6Gk89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##import necessary libraries"
      ],
      "metadata": {
        "id": "Jf6mLAr-lsSa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmfB3Q5xGXAy"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##accessing paths of all 4 debris types + split entire Taco Dataset into train and validation 80-20 split"
      ],
      "metadata": {
        "id": "UkAsKwFLl6yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#processing images\n",
        "bottles1 = '/content/drive/MyDrive/TEAM9SURESTART/taco/bottles'\n",
        "cans1 = '/content/drive/MyDrive/TEAM9SURESTART/taco/cans'\n",
        "containers1 = '/content/drive/MyDrive/TEAM9SURESTART/taco/containers'\n",
        "#paper1 = '/content/drive/MyDrive/TEAM9SURESTART/taco/paper'\n",
        "plastic1 = '/content/drive/MyDrive/TEAM9SURESTART/taco/plastic'\n",
        "\n",
        "bottles = [cv2.imread(image) for image in glob.glob(bottles1)]\n",
        "cans = [cv2.imread(image) for image in glob.glob(cans1)]\n",
        "containers = [cv2.imread(image) for image in glob.glob(containers1)]\n",
        "#paper = [cv2.imread(image) for image in glob.glob(paper1)]\n",
        "plastic = [cv2.imread(image) for image in glob.glob(plastic1)]\n",
        "\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/TEAM9SURESTART/taco',\n",
        "    validation_split = 0.2,\n",
        "    subset = \"training\",\n",
        "    seed = 24,  \n",
        "    image_size = (256, 256),\n",
        "    batch_size = 8\n",
        ")\n",
        "\n",
        "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/TEAM9SURESTART/taco',\n",
        "    validation_split = 0.2,\n",
        "    subset = \"validation\",\n",
        "    seed = 24,  \n",
        "    image_size = (256, 256),\n",
        "    batch_size = 8\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = train_dataset.cache().shuffle(13).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.cache().shuffle(13).prefetch(buffer_size = tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "ULsUt1M8MwrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##model architecture\n",
        "\n",
        "###includes rescaling of input image shapes"
      ],
      "metadata": {
        "id": "8O4u8a0WmOkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential ([\n",
        "    \n",
        "    \n",
        "    layers.Rescaling(1./255, input_shape = (256, 256, 3)),\n",
        "    layers.Conv2D(16, 3, padding = 'same', activation = 'relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Conv2D(32, 3, padding = 'same', activation = 'relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Conv2D(16, 3, padding = 'same', activation = 'relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(32, activation = 'relu'),\n",
        "    layers.Dense(4, activation = 'softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ZF96cNbCmNid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##train model with 150 epochs"
      ],
      "metadata": {
        "id": "SVS2HKjzmWbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), metrics = ['accuracy'])\n",
        "'''\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=['accuracy'],  run_eagerly=True\n",
        ")\n",
        "\n",
        "'''\n",
        "model.fit (\n",
        "    train_dataset, \n",
        "    validation_data = val_dataset,\n",
        "    epochs = 150\n",
        ")\n"
      ],
      "metadata": {
        "id": "4CaGQFS2Hlk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##visualize train and validation loss and accuracy curves"
      ],
      "metadata": {
        "id": "K_bC_SbYmdUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = pd.DataFrame(model.history.history)\n",
        "\n",
        "#plotting the loss and accuracy \n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(loss[\"loss\"], label =\"Loss\")\n",
        "plt.plot(loss[\"val_loss\"], label = \"Validation_loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(loss['accuracy'],label = \"Training Accuracy\")\n",
        "plt.plot(loss['val_accuracy'], label =\"Validation_ Accuracy \")\n",
        "plt.legend()\n",
        "plt.title(\"Training-Validation Accuracy\")"
      ],
      "metadata": {
        "id": "JvWzB_usAAvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#save model as .h5 model for convenient web app deployment "
      ],
      "metadata": {
        "id": "lBtZzn4796LT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')\n",
        "\n",
        "'''\n",
        "#save to drive as h5 model tensorflow model\n",
        "model_to_be_saved=\"debridetec_model\" \n",
        "\n",
        "model.save('/content/drive/MyDrive/saved_models/'+model_to_be_saved+'.h5')\n",
        "'''"
      ],
      "metadata": {
        "id": "JinQv_JF94Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#web app"
      ],
      "metadata": {
        "id": "VWDr59ukqVd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
        "!pip install st-btn-select"
      ],
      "metadata": {
        "id": "sd-Vt7VZqYRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile app.py\n",
        "from datetime import datetime\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import glob\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "from datetime import date\n",
        "from st_btn_select import st_btn_select\n",
        "\n",
        "selection = st_btn_select(('CHECK YOUR PLANTS', 'PLANT DISEASES INFO', 'ABOUT OUR APP', 'CONTACT US'))\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "if selection == 'CHECK YOUR PLANTS':\n",
        "  \n",
        "    import base64\n",
        "    def add_bg_from_local(image_file):\n",
        "        with open(image_file, \"rb\") as image_file:\n",
        "            encoded_string = base64.b64encode(image_file.read())\n",
        "        st.markdown(\n",
        "        f\"\"\"\n",
        "        <style>\n",
        "        .stApp {{\n",
        "            background-image: url(data:image/{\"PNG\"};base64,{encoded_string.decode()});\n",
        "            background-size: cover\n",
        "        }}\n",
        "        </style>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "        )\n",
        "    add_bg_from_local('plantbackground.jpg')    \n",
        "      \n",
        "\n",
        "                              \n",
        "    st.markdown(\"\"\" <style> .font {\n",
        "    font-size:50px ; font-weight: 800; color: #2e0a06; background-color: #ff958a;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font\"> PlantDoc</p>', unsafe_allow_html=True)\n",
        "    \n",
        "    st.markdown(\"\"\" <style> .font2 {\n",
        "    font-size:20px; color: ##0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font2\">Created by Julia & Justin Huang</p>', unsafe_allow_html=True)\n",
        "    \n",
        "    \n",
        "      \n",
        "    \n",
        "\n",
        "    st.markdown(\"\"\" <style> .font3 {\n",
        "    font-size:35px ; font-weight: 600; color: #ff958a; background-color: #0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font3\">Detect if your plants have a disease or not via AI technology: receive a quick & convenient result within seconds!</p>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\" <style> .font5 {\n",
        "    font-size:25px ; font-weight: 600; color: #2e0a06; background-color: #fcf6f5;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font5\">Upload Plant Image Here</p>', unsafe_allow_html=True)\n",
        "    \n",
        "    image = st.file_uploader(label = \" \", type = ['png','jfif', 'jpg', 'jpeg', 'tif', 'tiff', 'raw', 'webp'])\n",
        "\n",
        "    def import_and_predict(image_data, model):\n",
        "        size = (100, 100)\n",
        "        #image = ImageOps.fit(image_data, size, Image.ANTIALIAS)\n",
        "        image = np.array(Image.open(image_data).resize((100, 100)))\n",
        "        img = tf.keras.utils.img_to_array(image)\n",
        "        img = tf.expand_dims(img, 0)\n",
        "        probs = model.predict(img)\n",
        "        score = tf.nn.softmax(probs[0])\n",
        "        text = (\"Shoethentic predicts that this is an image of a **{} shoe with {:.2f}% confidence**.\"\n",
        "        .format(class_names[np.argmax(score)], 100 * np.max(score)))\n",
        "        return text\n",
        "\n",
        "  \n",
        "\n",
        "    loaded_model = tf.keras.models.load_model('plant_disease_model2.h5')\n",
        "    class_names = [\n",
        "    'Tomato: Late Blight',\n",
        "    'Tomato: Septoria Leaf Spot',\n",
        "    'Tomato: Spider Mites/Two Spotted Spider Mite',\n",
        "    'Tomato: Yellow Leaf Curl Virus',\n",
        "    'Tomato: Bacterial Spot',\n",
        "    'Tomato: Healthy',\n",
        "    'Tomato: Target Spot',\n",
        "    'Potato: Late Blight',\n",
        "    'Potato: Early Blight',\n",
        "    'Tomato: Early Blight',\n",
        "\n",
        "    'Bell Pepper: Healthy',\n",
        "    'Bell Pepper: Bacterial Spot',\n",
        "    'Tomato: Leaf Mold',\n",
        "    'Tomato: Mosaic Virus',\n",
        "    'Potato: Healthy']\n",
        "\n",
        "\n",
        "    predictionText = \"Prediction: Waiting for an image upload\"\n",
        "\n",
        "    if image is not None:\n",
        "        st.image(image)\n",
        "        predictionText = (import_and_predict(Image.open(image), loaded_model))\n",
        "\n",
        "    st.markdown(predictionText)   \n",
        "    #st.markdown('<p class=\"font2\">predictionText</p>', unsafe_allow_html=True)\n",
        "    \n",
        "if selection == 'ABOUT OUR APP':\n",
        "    import base64\n",
        "    def add_bg_from_local(image_file):\n",
        "        with open(image_file, \"rb\") as image_file:\n",
        "            encoded_string = base64.b64encode(image_file.read())\n",
        "        st.markdown(\n",
        "        f\"\"\"\n",
        "        <style>\n",
        "        .stApp {{\n",
        "            background-image: url(data:image/{\"PNG\"};base64,{encoded_string.decode()});\n",
        "            background-size: cover\n",
        "        }}\n",
        "        </style>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "        )\n",
        "    add_bg_from_local('plantbackground.jpg')    \n",
        "    \n",
        "    st.markdown(\"\"\" <style> .font {\n",
        "    font-size:50px ; font-weight: 800; color: #7792E3; background-color: #fffafa;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font\">About PlantDoc</p>', unsafe_allow_html=True)\n",
        "   \n",
        "\n",
        "    st.markdown(\"\"\" <style> .font2 {\n",
        "    font-size:30px ; font-weight: 600; color: #0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font2\">About the Creators</p>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\" <style> .font3 {\n",
        "    font-size:20px ; color: #fffafa;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font3\">The web app and model are built by Julia and Justin Huang, high school coders.</p>', unsafe_allow_html=True)\n",
        "  \n",
        "    \n",
        "    \n",
        "    st.markdown(\"\"\" <style> .font2 {\n",
        "    font-size:30px ; font-weight: 600; color: #0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font2\">Mission</p>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\" <style> .font3 {\n",
        "    font-size:20px ;  color: #fffafa;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font3\">Due to the high usage of pesticides, many plant diseases have become resilient and more common. In addition, farmers, especially those living in isolated or rural parts of the world, may not know what or if a disease has affected their plant. Therefore it is essential to figure out what diseases are affecting plants so consumers do not get sick. So the goal of **Shoethentic** is to provide the farmers and gardeners an opportunity to check the conditions of each and every plant they tend to. **Shoethentic** aims to make this checking process simpler and more convenient by utilizing AI & machine learning.</p>', unsafe_allow_html=True)\n",
        "    \n",
        "    st.markdown(\"\"\" <style> .font2 {\n",
        "    font-size:30px ; font-weight: 600; color: #0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font2\">How PlantDoc was Built</p>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\" <style> .font3 {\n",
        "    font-size:20px ; color: #fffafa;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font3\">PlantDoc has two parts: the AI model and web app. The AI model is built using the TensorFlow framework in the Python Language while the web app is built using Streamlit using HTMl/CSS formatting. We trained the model in Google Colab on a dataset consisting of 15 types of plant conditions sourced from the PlantVillage dataset on Kaggle and deployed the model into the web app with Streamlit.</p>', unsafe_allow_html=True)\n",
        "    \n",
        "    st.markdown(\"\"\" <style> .font2 {\n",
        "    font-size:30px ; font-weight: 600; color: #0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font2\">Future of PlantDoc</p>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\" <style> .font3 {\n",
        "    font-size:20px ; color: #0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font3\">The accuracy of our CNN model is currently 92%, but we plan to improve the accuracy of the AI model even more. We also plan to partner with agricultural businesses so we can test out the app with farmers.</p>', unsafe_allow_html=True)\n",
        "    \n",
        "    \n",
        "if selection == 'PLANT DISEASES INFO':\n",
        "    import base64\n",
        "    def add_bg_from_local(image_file):\n",
        "        with open(image_file, \"rb\") as image_file:\n",
        "            encoded_string = base64.b64encode(image_file.read())\n",
        "        st.markdown(\n",
        "        f\"\"\"\n",
        "        <style>\n",
        "        .stApp {{\n",
        "            background-image: url(data:image/{\"PNG\"};base64,{encoded_string.decode()});\n",
        "            background-size: cover\n",
        "        }}\n",
        "        </style>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "        )\n",
        "    add_bg_from_local('plantbackground.jpg')    \n",
        "    \n",
        "    st.markdown(\"\"\" <style> .font {\n",
        "    font-size:50px ; font-weight: 800; color: #7792E3; background-color: #fffafa;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font\">About Common Plant Disease + How to Prevent Them</p>', unsafe_allow_html=True)\n",
        "   \n",
        "\n",
        "    st.markdown(\"\"\" <style> .font2 {\n",
        "    font-size:30px ; font-weight: 600; color: #0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font2\">About the Creators</p>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\" <style> .font3 {\n",
        "    font-size:20px ; color: #fffafa;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font3\">The information page states relevant information for gardeners and farmers about the details of each disease and tips on how to prevent disease when growing plants. </p>', unsafe_allow_html=True)\n",
        "  \n",
        "    \n",
        "    \n",
        "    st.markdown(\"\"\" <style> .font2 {\n",
        "    font-size:30px ; font-weight: 600; color: #0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font2\">Mission</p>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\" <style> .font3 {\n",
        "    font-size:20px ;  color: #fffafa;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font3\">Due to the high usage of pesticides, many plant diseases have become resilient and more common. In addition, farmers, especially those living in isolated or rural parts of the world, may not know what or if a disease has affected their plant. Therefore it is essential to figure out what diseases are affecting plants so consumers do not get sick. So the goal of PlantDoc is to provide the farmers and gardeners an opportunity to check the conditions of each and every plant they tend to. PlantDoc aims to make this checking process simpler and more convenient by utilizing AI & machine learning.</p>', unsafe_allow_html=True)\n",
        "    \n",
        "    st.markdown(\"\"\" <style> .font2 {\n",
        "    font-size:30px ; font-weight: 600; color: #0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font2\">How PlantDoc was Built</p>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\" <style> .font3 {\n",
        "    font-size:20px ; color: #fffafa;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font3\">PlantDoc has two parts: the AI model and web app. The AI model is built using the TensorFlow framework in the Python Language while the web app is built using Streamlit using HTMl/CSS formatting. We trained the model in Google Colab on a dataset consisting of 15 types of plant conditions sourced from the PlantVillage dataset on Kaggle and deployed the model into the web app with Streamlit.</p>', unsafe_allow_html=True)\n",
        "    \n",
        "    st.markdown(\"\"\" <style> .font2 {\n",
        "    font-size:30px ; font-weight: 600; color: #0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font2\">Future of PlantDoc</p>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\" <style> .font3 {\n",
        "    font-size:20px ; color: #0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font3\">The accuracy of our CNN model is currently 92%, but we plan to improve the accuracy of the AI model even more. We also plan to partner with agricultural businesses so we can test out the app with farmers.</p>', unsafe_allow_html=True)\n",
        "    \n",
        "    \n",
        "       \n",
        "if selection == 'CONTACT US':\n",
        "    import base64\n",
        "    def add_bg_from_local(image_file):\n",
        "        with open(image_file, \"rb\") as image_file:\n",
        "            encoded_string = base64.b64encode(image_file.read())\n",
        "        st.markdown(\n",
        "        f\"\"\"\n",
        "        <style>\n",
        "        .stApp {{\n",
        "            background-image: url(data:image/{\"PNG\"};base64,{encoded_string.decode()});\n",
        "            background-size: cover\n",
        "        }}\n",
        "        </style>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "        )\n",
        "    add_bg_from_local('plantbackground.jpg')    \n",
        "    \n",
        "    st.markdown(\"\"\" <style> .font {\n",
        "    font-size:50px ; font-weight: 800; color: #7792E3; background-color: #fffafa;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font\">Contact PlantDoc Creators</p>', unsafe_allow_html=True)\n",
        "   \n",
        "\n",
        "    st.markdown(\"\"\" <style> .font2 {\n",
        "    font-size:30px ; font-weight: 600; color: #0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font2\">About the Creators</p>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\" <style> .font3 {\n",
        "    font-size:20px ; color: #fffafa;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font3\"> Have a question? Email us for questions, website bugs, or concerns.</p>', unsafe_allow_html=True)\n",
        "  \n",
        "    \n",
        "    \n",
        "    st.markdown(\"\"\" <style> .font2 {\n",
        "    font-size:30px ; font-weight: 600; color: #0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font2\">Mission</p>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\" <style> .font3 {\n",
        "    font-size:20px ;  color: #fffafa;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font3\">Due to the high usage of pesticides, many plant diseases have become resilient and more common. In addition, farmers, especially those living in isolated or rural parts of the world, may not know what or if a disease has affected their plant. Therefore it is essential to figure out what diseases are affecting plants so consumers do not get sick. So the goal of PlantDoc is to provide the farmers and gardeners an opportunity to check the conditions of each and every plant they tend to. PlantDoc aims to make this checking process simpler and more convenient by utilizing AI & machine learning.</p>', unsafe_allow_html=True)\n",
        "    \n",
        "    st.markdown(\"\"\" <style> .font2 {\n",
        "    font-size:30px ; font-weight: 600; color: #0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font2\">How PlantDoc was Built</p>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\" <style> .font3 {\n",
        "    font-size:20px ; color: #fffafa;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font3\">PlantDoc has two parts: the AI model and web app. The AI model is built using the TensorFlow framework in the Python Language while the web app is built using Streamlit using HTMl/CSS formatting. We trained the model in Google Colab on a dataset consisting of 15 types of plant conditions sourced from the PlantVillage dataset on Kaggle and deployed the model into the web app with Streamlit.</p>', unsafe_allow_html=True)\n",
        "    \n",
        "    st.markdown(\"\"\" <style> .font2 {\n",
        "    font-size:30px ; font-weight: 600; color: #0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font2\">Future of PlantDoc</p>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\" <style> .font3 {\n",
        "    font-size:20px ; color: #0a0302;} \n",
        "    </style> \"\"\", unsafe_allow_html=True)\n",
        "    st.markdown('<p class=\"font3\">The accuracy of our CNN model is currently 92%, but we plan to improve the accuracy of the AI model even more. We also plan to partner with agricultural businesses so we can test out the app with farmers.</p>', unsafe_allow_html=True)\n",
        "    \n",
        "    \n",
        "     \n"
      ],
      "metadata": {
        "id": "XuxbBcLcqVNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "! pip install -q streamlit\n",
        "!mkdir -p /drive/ngrok-ssh\n",
        "%cd /drive/ngrok-ssh\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip -O ngrok-stable-linux-amd64.zip\n",
        "!unzip -u ngrok-stable-linux-amd64.zip\n",
        "!cp /drive/ngrok-ssh/ngrok /ngrok\n",
        "!chmod +x /ngrok\n",
        "!/ngrok authtoken 2Fud0KVvq9S56Na5IbL6NRnHZtZ_6KvuGdz8px9MHULrMeHWf\n",
        "from pyngrok import ngrok\n",
        "#Publish Web App (Run this again whenever you make changes)\n",
        "public_url = ngrok.connect(port='180')\n",
        "print (public_url)\n",
        "! streamlit run --server.port 180 app.py"
      ],
      "metadata": {
        "id": "v-EoswxRqbG2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}